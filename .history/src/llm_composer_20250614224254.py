"""
å¤§æ¨¡å‹æœåŠ¡ç»„åˆæ¨¡å—
åŸºäºå¤§æ¨¡å‹è¿›è¡Œç‰©è”ç½‘æœåŠ¡ç»„åˆï¼Œæ”¯æŒæç¤ºè¯å·¥ç¨‹å’ŒæœåŠ¡è‡ªåŠ¨ç»„åˆ
"""

import json
from langchain_core.prompts import PromptTemplate
import time
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import requests
from dataclasses import dataclass
import openai
from openai import OpenAI

openai.api_key = "sk-SCDwjRxMzieVmaWAWV9iqnqDXFd41XV8j3uS6RnnrmknF7fp"
openai.base_url = "https://dzqc.link/v1"


@dataclass
class IoTService:
    """ç‰©è”ç½‘æœåŠ¡å®šä¹‰"""
    id: str
    name: str
    description: str
    inputs: List[str]
    outputs: List[str]
    category: str
    requirements: List[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'id': self.id,
            'name': self.name,
            'description': self.description,
            'inputs': self.inputs,
            'outputs': self.outputs,
            'category': self.category,
            'requirements': self.requirements or []
        }

class LLMServiceComposer:
    """å¤§æ¨¡å‹æœåŠ¡ç»„åˆå™¨"""
    
    def __init__(self, config_path: str = "config/service_config.json"):
        """
        åˆå§‹åŒ–æœåŠ¡ç»„åˆå™¨
        
        Args:
            config_path: æœåŠ¡é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config = self._load_config(config_path)
        self.llm_config = self.config.get('llm_service', {})
        
        # å¯ç”¨æœåŠ¡åº“
        self.available_services = self._load_available_services()
        
        # ç»„åˆå†å²
        self.composition_history = []
        
        # æ¨¡å‹é…ç½®
        self.model_type = self.llm_config.get('model_type', 'gpt-3.5-turbo')
        self.api_key = self.llm_config.get('api_key', '')
        self.base_url = self.llm_config.get('base_url', 'https://api.openai.com/v1')
        self.max_tokens = self.llm_config.get('max_tokens', 1000)
        self.temperature = self.llm_config.get('temperature', 0.7)
        
        # æç¤ºè¯æ¨¡æ¿
        self.prompt_templates = self._load_prompt_templates()
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def _load_available_services(self) -> List[IoTService]:
        """åŠ è½½å¯ç”¨æœåŠ¡"""
        # é¢„å®šä¹‰çš„ç‰©è”ç½‘æœåŠ¡
        services = [
            IoTService(
                id="temperature_monitor",
                name="æ¸©åº¦ç›‘æ§æœåŠ¡",
                description="ç›‘æ§ç¯å¢ƒæ¸©åº¦ï¼Œæä¾›å®æ—¶æ¸©åº¦æ•°æ®å’Œå¼‚å¸¸æŠ¥è­¦",
                inputs=["sensor_data"],
                outputs=["temperature_value", "temperature_status", "alert"],
                category="monitoring"
            ),
            IoTService(
                id="humidity_control",
                name="æ¹¿åº¦æ§åˆ¶æœåŠ¡",
                description="æ§åˆ¶ç¯å¢ƒæ¹¿åº¦ï¼Œè‡ªåŠ¨è°ƒèŠ‚åŠ æ¹¿/é™¤æ¹¿è®¾å¤‡",
                inputs=["humidity_data", "target_humidity"],
                outputs=["control_command", "adjustment_status"],
                category="control"
            ),
            IoTService(
                id="fire_detection",
                name="ç«ç¾æ£€æµ‹æœåŠ¡",
                description="åŸºäºçƒŸé›¾å’Œæ¸©åº¦ä¼ æ„Ÿå™¨æ£€æµ‹ç«ç¾é£é™©",
                inputs=["smoke_data", "temperature_data"],
                outputs=["fire_risk_level", "emergency_alert"],
                category="safety"
            ),
            IoTService(
                id="energy_optimization",
                name="èƒ½æºä¼˜åŒ–æœåŠ¡",
                description="åŸºäºå ç”¨æƒ…å†µå’Œç¯å¢ƒæ¡ä»¶ä¼˜åŒ–èƒ½æºä½¿ç”¨",
                inputs=["motion_data", "light_data", "schedule"],
                outputs=["energy_plan", "device_commands"],
                category="optimization"
            ),
            IoTService(
                id="comfort_management",
                name="èˆ’é€‚åº¦ç®¡ç†æœåŠ¡",
                description="ç»¼åˆç®¡ç†æ¸©åº¦ã€æ¹¿åº¦ã€å…‰ç…§ï¼Œç»´æŒèˆ’é€‚ç¯å¢ƒ",
                inputs=["temperature_data", "humidity_data", "light_data", "user_preferences"],
                outputs=["comfort_score", "adjustment_recommendations"],
                category="comfort"
            ),
            IoTService(
                id="security_monitoring",
                name="å®‰å…¨ç›‘æ§æœåŠ¡",
                description="ç›‘æ§äººå‘˜æ´»åŠ¨ï¼Œæ£€æµ‹å¼‚å¸¸è¡Œä¸º",
                inputs=["motion_data", "door_sensor", "time_schedule"],
                outputs=["security_status", "intrusion_alert"],
                category="security"
            ),
            IoTService(
                id="data_analytics",
                name="æ•°æ®åˆ†ææœåŠ¡",
                description="åˆ†æä¼ æ„Ÿå™¨æ•°æ®è¶‹åŠ¿ï¼Œæä¾›æ´å¯Ÿå’Œé¢„æµ‹",
                inputs=["historical_data", "sensor_readings"],
                outputs=["trend_analysis", "predictions", "insights"],
                category="analytics"
            ),
            IoTService(
                id="notification_service",
                name="é€šçŸ¥æœåŠ¡",
                description="å‘é€å„ç§ç±»å‹çš„é€šçŸ¥å’Œè­¦æŠ¥",
                inputs=["alert_data", "notification_config"],
                outputs=["notification_sent", "delivery_status"],
                category="communication"
            ),
            IoTService(
                id="device_control",
                name="è®¾å¤‡æ§åˆ¶æœåŠ¡",
                description="æ§åˆ¶å„ç§æ™ºèƒ½è®¾å¤‡çš„å¼€å…³å’Œå‚æ•°",
                inputs=["device_id", "control_command", "parameters"],
                outputs=["execution_status", "device_response"],
                category="control"
            ),
            IoTService(
                id="scheduling_service",
                name="è°ƒåº¦æœåŠ¡",
                description="æ ¹æ®æ—¶é—´è¡¨å’Œæ¡ä»¶è‡ªåŠ¨æ‰§è¡Œä»»åŠ¡",
                inputs=["schedule_config", "trigger_conditions"],
                outputs=["scheduled_tasks", "execution_log"],
                category="automation"
            )
        ]
        
        return services
    
    def _load_prompt_templates(self) -> Dict[str, str]:
        """åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        return {
            "service_composition": """
ä½œä¸ºæ™ºèƒ½å®¶å±…ç³»ç»Ÿçš„æœåŠ¡ç»„åˆä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªæœåŠ¡ç»„åˆæ–¹æ¡ˆï¼š

**ç›®æ ‡éœ€æ±‚ï¼š**
{target_goal}

**å½“å‰ä¼ æ„Ÿå™¨æ•°æ®ï¼š**
{sensor_data}

**å¯ç”¨æœåŠ¡åˆ—è¡¨ï¼š**
{available_services}

**çº¦æŸæ¡ä»¶ï¼š**
{constraints}

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æä¾›æœåŠ¡ç»„åˆæ–¹æ¡ˆï¼š

## æœåŠ¡ç»„åˆæ–¹æ¡ˆ

### 1. æ–¹æ¡ˆæ¦‚è¿°
- æ–¹æ¡ˆåç§°ï¼š[ä¸ºæ–¹æ¡ˆèµ·ä¸€ä¸ªæè¿°æ€§åç§°]
- ä¸»è¦ç›®æ ‡ï¼š[ç®€è¿°æ–¹æ¡ˆè¦è¾¾æˆçš„ç›®æ ‡]
- é¢„æœŸæ•ˆæœï¼š[æè¿°é¢„æœŸçš„æ•ˆæœå’Œæ”¶ç›Š]

### 2. æœåŠ¡ç»„åˆ
è¯·é€‰æ‹©å¹¶ç»„åˆä»¥ä¸‹æœåŠ¡ï¼š
```json
{{
  "composition_id": "å”¯ä¸€æ ‡è¯†ç¬¦",
  "services": [
    {{
      "service_id": "æœåŠ¡ID",
      "service_name": "æœåŠ¡åç§°",
      "role": "åœ¨ç»„åˆä¸­çš„ä½œç”¨",
      "priority": "ä¼˜å…ˆçº§(1-5)",
      "inputs": ["è¾“å…¥æ•°æ®"],
      "outputs": ["è¾“å‡ºæ•°æ®"],
      "dependencies": ["ä¾èµ–çš„å…¶ä»–æœåŠ¡ID"]
    }}
  ],
  "execution_flow": "æ‰§è¡Œæµç¨‹æè¿°",
  "data_flow": "æ•°æ®æµè½¬è¯´æ˜"
}}
```

### 3. å®æ–½å»ºè®®
- éƒ¨ç½²é¡ºåºï¼š[è¯´æ˜æœåŠ¡éƒ¨ç½²çš„å…ˆåé¡ºåº]
- é…ç½®è¦ç‚¹ï¼š[å…³é”®é…ç½®å‚æ•°]
- ç›‘æ§æŒ‡æ ‡ï¼š[éœ€è¦ç›‘æ§çš„å…³é”®æŒ‡æ ‡]
- é£é™©è¯„ä¼°ï¼š[æ½œåœ¨é£é™©å’Œåº”å¯¹æªæ–½]

è¯·ç¡®ä¿æ–¹æ¡ˆåˆ‡å®å¯è¡Œï¼ŒæœåŠ¡ä¹‹é—´çš„æ•°æ®æµè½¬åˆç†ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ»¡è¶³ç›®æ ‡éœ€æ±‚ã€‚
""",
            
            "service_optimization": """
åŸºäºä»¥ä¸‹è¿è¡Œæ•°æ®ï¼Œè¯·ä¼˜åŒ–ç°æœ‰çš„æœåŠ¡ç»„åˆï¼š

**å½“å‰æœåŠ¡ç»„åˆï¼š**
{current_composition}

**è¿è¡Œç»Ÿè®¡æ•°æ®ï¼š**
{performance_data}

**ç”¨æˆ·åé¦ˆï¼š**
{user_feedback}

**ä¼˜åŒ–ç›®æ ‡ï¼š**
{optimization_goals}

è¯·æä¾›ä¼˜åŒ–å»ºè®®ï¼š

## ä¼˜åŒ–å»ºè®®

### 1. æ€§èƒ½åˆ†æ
- å½“å‰æ€§èƒ½è¯„ä¼°
- ç“¶é¢ˆè¯†åˆ«
- æ”¹è¿›ç©ºé—´

### 2. ä¼˜åŒ–æ–¹æ¡ˆ
- æœåŠ¡è°ƒæ•´å»ºè®®
- å‚æ•°ä¼˜åŒ–
- æµç¨‹æ”¹è¿›

### 3. é¢„æœŸæ•ˆæœ
- æ€§èƒ½æå‡é¢„æœŸ
- ç”¨æˆ·ä½“éªŒæ”¹å–„
- èµ„æºåˆ©ç”¨ä¼˜åŒ–
""",
            
            "trouble_shooting": """
è¯·å¸®åŠ©è¯Šæ–­å’Œè§£å†³ä»¥ä¸‹æœåŠ¡ç»„åˆé—®é¢˜ï¼š

**é—®é¢˜æè¿°ï¼š**
{problem_description}

**é”™è¯¯ä¿¡æ¯ï¼š**
{error_messages}

**ç›¸å…³æœåŠ¡ï¼š**
{related_services}

**ç³»ç»ŸçŠ¶æ€ï¼š**
{system_status}

è¯·æä¾›æ•…éšœæ’é™¤æ–¹æ¡ˆï¼š

## æ•…éšœè¯Šæ–­

### 1. é—®é¢˜åˆ†æ
- é—®é¢˜æ ¹å› åˆ†æ
- å½±å“èŒƒå›´è¯„ä¼°
- ç´§æ€¥ç¨‹åº¦åˆ¤æ–­

### 2. è§£å†³æ–¹æ¡ˆ
- ç«‹å³æªæ–½
- é•¿æœŸä¿®å¤
- é¢„é˜²æªæ–½

### 3. æ¢å¤æ­¥éª¤
- è¯¦ç»†æ“ä½œæ­¥éª¤
- éªŒè¯æ–¹æ³•
- å›æ»šè®¡åˆ’
"""
        }
    
    def compose_services(self, target_goal: str, sensor_data: Dict[str, Any] = None, 
                        constraints: List[str] = None) -> Dict[str, Any]:
        """
        åŸºäºç›®æ ‡éœ€æ±‚ç»„åˆæœåŠ¡
        
        Args:
            target_goal: ç›®æ ‡éœ€æ±‚æè¿°
            sensor_data: å½“å‰ä¼ æ„Ÿå™¨æ•°æ®
            constraints: çº¦æŸæ¡ä»¶
            
        Returns:
            æœåŠ¡ç»„åˆæ–¹æ¡ˆ
        """
        print(f"ğŸ¯ å¼€å§‹ç”ŸæˆæœåŠ¡ç»„åˆ...")
        print(f"ğŸ“ ç›®æ ‡éœ€æ±‚: {target_goal}")
        
        # å‡†å¤‡æç¤ºè¯
        prompt = self._prepare_composition_prompt(target_goal, sensor_data, constraints)
        
        # è°ƒç”¨å¤§æ¨¡å‹
        print(f"ğŸ¤– æ­£åœ¨è°ƒç”¨AIæ¨¡å‹ç”Ÿæˆæ–¹æ¡ˆ...")
        llm_response = self._call_llm(prompt)
        
        # è§£æå“åº”
        composition = self._parse_composition_response(llm_response)
        
        # # éªŒè¯ç»„åˆå¯è¡Œæ€§
        # validated_composition = self._validate_composition(composition)
        
        # # ç¾åŒ–è¾“å‡ºç»“æœ
        # self._record_composition(validated_composition, target_goal)
        
        return llm_response
    
    def _prepare_composition_prompt(self, target_goal: str, sensor_data: Dict[str, Any] = None, 
                                  constraints: List[str] = None) -> str:
        """å‡†å¤‡æœåŠ¡ç»„åˆæç¤ºè¯"""
        # æ ¼å¼åŒ–ä¼ æ„Ÿå™¨æ•°æ®
        sensor_data_str = json.dumps(sensor_data or {}, indent=2, ensure_ascii=False)
        
        # æ ¼å¼åŒ–å¯ç”¨æœåŠ¡
        services_str = ""
        for service in self.available_services:
            services_str += f"- **{service.name}** ({service.id}): {service.description}\n"
            services_str += f"  è¾“å…¥: {', '.join(service.inputs)}\n"
            services_str += f"  è¾“å‡º: {', '.join(service.outputs)}\n"
            services_str += f"  ç±»åˆ«: {service.category}\n\n"
        
        # æ ¼å¼åŒ–çº¦æŸæ¡ä»¶
        constraints_str = "\n".join(f"- {constraint}" for constraint in (constraints or []))
        
        # å¡«å……æ¨¡æ¿
        prompt = self.prompt_templates["service_composition"].format(
            target_goal=target_goal,
            sensor_data=sensor_data_str,
            available_services=services_str,
            constraints=constraints_str
        )
        print(prompt)
        return prompt
    
    def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹"""
        # è¿™é‡Œå®ç°å¯¹ä¸åŒLLMçš„è°ƒç”¨
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªå“åº”
        if self.model_type.startswith('gpt'):
            return self._call_openai_api(prompt)
        else:
            return self._simulate_llm_response(prompt)
    
    def _call_openai_api(self, prompt: str) -> str:
        """è°ƒç”¨OpenAI API"""
        if not self.api_key or self.api_key == "your-api-key-here":
            print("ğŸ”„ ä½¿ç”¨æ¨¡æ‹Ÿå“åº”æ¨¡å¼ï¼ˆæœªé…ç½®æœ‰æ•ˆAPIå¯†é’¥ï¼‰")
            return self._simulate_llm_response(prompt)
        
        try:
            headers = {
                'Authorization': f'Bearer {self.api_key}',
                'Content-Type': 'application/json'
            }

            llm = OpenAI(model='gpt-4o-mini',api_key=self.api_key, base_url=self.base_url)
            response=llm.invoke(prompt)
            print(response)
            return llm.invoke(prompt)

            # response = llm.chat.completions.create(
            #     model="gpt-4o-mini",
            #     messages=[
            #         {"role": "system", "content": prompt}
            #     ]
            # )

            # response = requests.post(
            #     f'{self.base_url}/chat/completions',
            #     headers=headers,
            #     json=data,
            #     timeout=30
            # )
            
            if response.status_code == 200:
                result = response.json()
                print(f"âœ… APIè°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(result.get('choices', []))} ä¸ªé€‰æ‹©")
                return result['choices'][0]['message']['content']
            else:
                print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                if response.text:
                    print(f"é”™è¯¯è¯¦æƒ…: {response.text[:200]}...")
                print("ğŸ”„ åˆ‡æ¢åˆ°æ¨¡æ‹Ÿå“åº”æ¨¡å¼")
                return self._simulate_llm_response(prompt)
                
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¼‚å¸¸: {e}")
            print("ğŸ”„ åˆ‡æ¢åˆ°æ¨¡æ‹Ÿå“åº”æ¨¡å¼")
            return self._simulate_llm_response(prompt)
    
    def _simulate_llm_response(self, prompt: str) -> str:
        """æ¨¡æ‹ŸLLMå“åº”ï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        # æ ¹æ®æç¤ºè¯å†…å®¹ç”Ÿæˆæ¨¡æ‹Ÿå“åº”
        if "ç«ç¾" in prompt or "fire" in prompt.lower():
            return self._generate_fire_safety_composition()
        elif "èˆ’é€‚" in prompt or "comfort" in prompt.lower():
            return self._generate_comfort_composition()
        elif "èŠ‚èƒ½" in prompt or "energy" in prompt.lower():
            return self._generate_energy_composition()
        else:
            return self._generate_default_composition()
    
    def _generate_fire_safety_composition(self) -> str:
        """ç”Ÿæˆç«ç¾å®‰å…¨æœåŠ¡ç»„åˆç¤ºä¾‹"""
        return """
## æœåŠ¡ç»„åˆæ–¹æ¡ˆ

### 1. æ–¹æ¡ˆæ¦‚è¿°
- æ–¹æ¡ˆåç§°ï¼šæ™ºèƒ½ç«ç¾å®‰å…¨é˜²æŠ¤ç³»ç»Ÿ
- ä¸»è¦ç›®æ ‡ï¼šå®æ—¶ç›‘æ§ç«ç¾é£é™©ï¼Œå¿«é€Ÿå“åº”å’Œå¤„ç†ç«ç¾äº‹ä»¶
- é¢„æœŸæ•ˆæœï¼šæé«˜ç«ç¾æ£€æµ‹ç²¾åº¦ï¼Œç¼©çŸ­å“åº”æ—¶é—´ï¼Œä¿éšœäººå‘˜å®‰å…¨

### 2. æœåŠ¡ç»„åˆ
```json
{
  "composition_id": "fire_safety_system_001",
  "services": [
    {
      "service_id": "fire_detection",
      "service_name": "ç«ç¾æ£€æµ‹æœåŠ¡",
      "role": "æ ¸å¿ƒæ£€æµ‹ç»„ä»¶",
      "priority": 5,
      "inputs": ["smoke_data", "temperature_data"],
      "outputs": ["fire_risk_level", "emergency_alert"],
      "dependencies": []
    },
    {
      "service_id": "notification_service",
      "service_name": "é€šçŸ¥æœåŠ¡",
      "role": "ç´§æ€¥é€šçŸ¥",
      "priority": 5,
      "inputs": ["alert_data", "notification_config"],
      "outputs": ["notification_sent", "delivery_status"],
      "dependencies": ["fire_detection"]
    },
    {
      "service_id": "device_control",
      "service_name": "è®¾å¤‡æ§åˆ¶æœåŠ¡",
      "role": "å®‰å…¨è®¾å¤‡æ§åˆ¶",
      "priority": 4,
      "inputs": ["device_id", "control_command", "parameters"],
      "outputs": ["execution_status", "device_response"],
      "dependencies": ["fire_detection"]
    },
    {
      "service_id": "data_analytics",
      "service_name": "æ•°æ®åˆ†ææœåŠ¡",
      "role": "é£é™©è¯„ä¼°",
      "priority": 3,
      "inputs": ["historical_data", "sensor_readings"],
      "outputs": ["trend_analysis", "predictions", "insights"],
      "dependencies": []
    }
  ],
  "execution_flow": "ç«ç¾æ£€æµ‹æœåŠ¡æŒç»­ç›‘æ§ -> æ£€æµ‹åˆ°é£é™©æ—¶è§¦å‘é€šçŸ¥æœåŠ¡å’Œè®¾å¤‡æ§åˆ¶ -> æ•°æ®åˆ†ææœåŠ¡æä¾›å†³ç­–æ”¯æŒ",
  "data_flow": "ä¼ æ„Ÿå™¨æ•°æ® -> ç«ç¾æ£€æµ‹ -> é£é™©è¯„ä¼° -> é€šçŸ¥+æ§åˆ¶æŒ‡ä»¤"
}
```

### 3. å®æ–½å»ºè®®
- éƒ¨ç½²é¡ºåºï¼šæ•°æ®åˆ†ææœåŠ¡ -> ç«ç¾æ£€æµ‹æœåŠ¡ -> é€šçŸ¥æœåŠ¡ -> è®¾å¤‡æ§åˆ¶æœåŠ¡
- é…ç½®è¦ç‚¹ï¼šè®¾ç½®åˆç†çš„é˜ˆå€¼ï¼Œé…ç½®å¤šç§é€šçŸ¥æ¸ é“ï¼Œç¡®ä¿è®¾å¤‡æ§åˆ¶çš„å¯é æ€§
- ç›‘æ§æŒ‡æ ‡ï¼šæ£€æµ‹å“åº”æ—¶é—´ã€è¯¯æŠ¥ç‡ã€é€šçŸ¥é€è¾¾ç‡ã€è®¾å¤‡æ‰§è¡ŒæˆåŠŸç‡
- é£é™©è¯„ä¼°ï¼šé¿å…è¯¯æŠ¥å½±å“ç”¨æˆ·ä½“éªŒï¼Œç¡®ä¿ç´§æ€¥æƒ…å†µä¸‹çš„å¯é æ€§
"""
    
    def _generate_comfort_composition(self) -> str:
        """ç”Ÿæˆèˆ’é€‚åº¦ç®¡ç†æœåŠ¡ç»„åˆç¤ºä¾‹"""
        return """
## æœåŠ¡ç»„åˆæ–¹æ¡ˆ

### 1. æ–¹æ¡ˆæ¦‚è¿°
- æ–¹æ¡ˆåç§°ï¼šæ™ºèƒ½èˆ’é€‚åº¦ç®¡ç†ç³»ç»Ÿ
- ä¸»è¦ç›®æ ‡ï¼šç»´æŒæœ€ä½³ç¯å¢ƒèˆ’é€‚åº¦ï¼Œæå‡å±…ä½ä½“éªŒ
- é¢„æœŸæ•ˆæœï¼šè‡ªåŠ¨è°ƒèŠ‚ç¯å¢ƒå‚æ•°ï¼Œæé«˜ç”Ÿæ´»è´¨é‡ï¼Œé™ä½èƒ½æºæ¶ˆè€—

### 2. æœåŠ¡ç»„åˆ
```json
{
  "composition_id": "comfort_management_001",
  "services": [
    {
      "service_id": "comfort_management",
      "service_name": "èˆ’é€‚åº¦ç®¡ç†æœåŠ¡",
      "role": "æ ¸å¿ƒç®¡ç†ç»„ä»¶",
      "priority": 5,
      "inputs": ["temperature_data", "humidity_data", "light_data", "user_preferences"],
      "outputs": ["comfort_score", "adjustment_recommendations"],
      "dependencies": []
    },
    {
      "service_id": "temperature_monitor",
      "service_name": "æ¸©åº¦ç›‘æ§æœåŠ¡",
      "role": "æ¸©åº¦æ•°æ®æä¾›",
      "priority": 4,
      "inputs": ["sensor_data"],
      "outputs": ["temperature_value", "temperature_status", "alert"],
      "dependencies": []
    },
    {
      "service_id": "humidity_control",
      "service_name": "æ¹¿åº¦æ§åˆ¶æœåŠ¡",
      "role": "æ¹¿åº¦è°ƒèŠ‚",
      "priority": 4,
      "inputs": ["humidity_data", "target_humidity"],
      "outputs": ["control_command", "adjustment_status"],
      "dependencies": ["comfort_management"]
    },
    {
      "service_id": "device_control",
      "service_name": "è®¾å¤‡æ§åˆ¶æœåŠ¡",
      "role": "ç¯å¢ƒè®¾å¤‡æ§åˆ¶",
      "priority": 4,
      "inputs": ["device_id", "control_command", "parameters"],
      "outputs": ["execution_status", "device_response"],
      "dependencies": ["comfort_management", "humidity_control"]
    }
  ],
  "execution_flow": "ä¼ æ„Ÿå™¨ç›‘æ§ -> èˆ’é€‚åº¦è¯„ä¼° -> ç”Ÿæˆè°ƒèŠ‚æ–¹æ¡ˆ -> æ‰§è¡Œè®¾å¤‡æ§åˆ¶",
  "data_flow": "ç¯å¢ƒæ•°æ® -> èˆ’é€‚åº¦åˆ†æ -> æ§åˆ¶ç­–ç•¥ -> è®¾å¤‡æ‰§è¡Œ"
}
```

### 3. å®æ–½å»ºè®®
- éƒ¨ç½²é¡ºåºï¼šæ¸©åº¦ç›‘æ§ -> èˆ’é€‚åº¦ç®¡ç† -> æ¹¿åº¦æ§åˆ¶ -> è®¾å¤‡æ§åˆ¶
- é…ç½®è¦ç‚¹ï¼šè®¾å®šä¸ªäººåå¥½å‚æ•°ï¼Œé…ç½®è®¾å¤‡æ§åˆ¶ç­–ç•¥ï¼Œè®¾ç½®èŠ‚èƒ½æ¨¡å¼
- ç›‘æ§æŒ‡æ ‡ï¼šèˆ’é€‚åº¦è¯„åˆ†ã€èƒ½è€—æ°´å¹³ã€ç”¨æˆ·æ»¡æ„åº¦ã€è®¾å¤‡è¿è¡Œæ•ˆç‡
- é£é™©è¯„ä¼°ï¼šé¿å…é¢‘ç¹è°ƒèŠ‚å½±å“è®¾å¤‡å¯¿å‘½ï¼Œå¹³è¡¡èˆ’é€‚åº¦å’Œèƒ½è€—
"""
    
    def _generate_energy_composition(self) -> str:
        """ç”ŸæˆèŠ‚èƒ½æœåŠ¡ç»„åˆç¤ºä¾‹"""
        return """
## æœåŠ¡ç»„åˆæ–¹æ¡ˆ

### 1. æ–¹æ¡ˆæ¦‚è¿°
- æ–¹æ¡ˆåç§°ï¼šæ™ºèƒ½èŠ‚èƒ½ä¼˜åŒ–ç³»ç»Ÿ
- ä¸»è¦ç›®æ ‡ï¼šæœ€å¤§åŒ–èƒ½æºåˆ©ç”¨æ•ˆç‡ï¼Œé™ä½èƒ½è€—æˆæœ¬
- é¢„æœŸæ•ˆæœï¼šèŠ‚çœ15-30%èƒ½æºæ¶ˆè€—ï¼Œæ™ºèƒ½åŒ–èƒ½æºç®¡ç†

### 2. æœåŠ¡ç»„åˆ
```json
{
  "composition_id": "energy_optimization_001",
  "services": [
    {
      "service_id": "energy_optimization",
      "service_name": "èƒ½æºä¼˜åŒ–æœåŠ¡",
      "role": "æ ¸å¿ƒä¼˜åŒ–å¼•æ“",
      "priority": 5,
      "inputs": ["motion_data", "light_data", "schedule"],
      "outputs": ["energy_plan", "device_commands"],
      "dependencies": []
    },
    {
      "service_id": "scheduling_service",
      "service_name": "è°ƒåº¦æœåŠ¡",
      "role": "ä»»åŠ¡è°ƒåº¦ç®¡ç†",
      "priority": 4,
      "inputs": ["schedule_config", "trigger_conditions"],
      "outputs": ["scheduled_tasks", "execution_log"],
      "dependencies": []
    },
    {
      "service_id": "device_control",
      "service_name": "è®¾å¤‡æ§åˆ¶æœåŠ¡",
      "role": "è®¾å¤‡æ‰§è¡Œæ§åˆ¶",
      "priority": 4,
      "inputs": ["device_id", "control_command", "parameters"],
      "outputs": ["execution_status", "device_response"],
      "dependencies": ["energy_optimization", "scheduling_service"]
    },
    {
      "service_id": "data_analytics",
      "service_name": "æ•°æ®åˆ†ææœåŠ¡",
      "role": "èƒ½è€—åˆ†æä¼˜åŒ–",
      "priority": 3,
      "inputs": ["historical_data", "sensor_readings"],
      "outputs": ["trend_analysis", "predictions", "insights"],
      "dependencies": []
    }
  ],
  "execution_flow": "æ•°æ®æ”¶é›† -> èƒ½æºåˆ†æ -> ä¼˜åŒ–ç­–ç•¥ -> è°ƒåº¦æ‰§è¡Œ -> æ•ˆæœè¯„ä¼°",
  "data_flow": "ä¼ æ„Ÿå™¨æ•°æ® -> èƒ½æºä¼˜åŒ–ç®—æ³• -> æ§åˆ¶ç­–ç•¥ -> è®¾å¤‡æ‰§è¡Œ -> åé¦ˆä¼˜åŒ–"
}
```

### 3. å®æ–½å»ºè®®
- éƒ¨ç½²é¡ºåºï¼šæ•°æ®åˆ†æ -> è°ƒåº¦æœåŠ¡ -> èƒ½æºä¼˜åŒ– -> è®¾å¤‡æ§åˆ¶
- é…ç½®è¦ç‚¹ï¼šè®¾ç½®èƒ½è€—åŸºçº¿ï¼Œé…ç½®ä¼˜åŒ–ç®—æ³•å‚æ•°ï¼Œå»ºç«‹ç”¨æˆ·è¡Œä¸ºæ¨¡å‹
- ç›‘æ§æŒ‡æ ‡ï¼šèƒ½è€—é™ä½ç‡ã€ç”¨æˆ·æ»¡æ„åº¦ã€è®¾å¤‡è¿è¡Œæ—¶é—´ã€æˆæœ¬èŠ‚çº¦
- é£é™©è¯„ä¼°ï¼šç¡®ä¿èˆ’é€‚åº¦ä¸å—å½±å“ï¼Œé¿å…è¿‡åº¦ä¼˜åŒ–å¯¼è‡´ç”¨æˆ·ä½“éªŒä¸‹é™
"""
    
    def _generate_default_composition(self) -> str:
        """ç”Ÿæˆé»˜è®¤æœåŠ¡ç»„åˆç¤ºä¾‹"""
        return """
## æœåŠ¡ç»„åˆæ–¹æ¡ˆ

### 1. æ–¹æ¡ˆæ¦‚è¿°
- æ–¹æ¡ˆåç§°ï¼šç»¼åˆæ™ºèƒ½å®¶å±…ç®¡ç†ç³»ç»Ÿ
- ä¸»è¦ç›®æ ‡ï¼šæä¾›å…¨é¢çš„æ™ºèƒ½å®¶å±…ç®¡ç†å’Œç›‘æ§
- é¢„æœŸæ•ˆæœï¼šæå‡å±…ä½ä½“éªŒï¼Œæé«˜å®‰å…¨æ€§ï¼Œä¼˜åŒ–èƒ½æºä½¿ç”¨

### 2. æœåŠ¡ç»„åˆ
```json
{
  "composition_id": "comprehensive_home_system_001",
  "services": [
    {
      "service_id": "temperature_monitor",
      "service_name": "æ¸©åº¦ç›‘æ§æœåŠ¡",
      "role": "ç¯å¢ƒç›‘æ§",
      "priority": 4,
      "inputs": ["sensor_data"],
      "outputs": ["temperature_value", "temperature_status", "alert"],
      "dependencies": []
    },
    {
      "service_id": "security_monitoring",
      "service_name": "å®‰å…¨ç›‘æ§æœåŠ¡",
      "role": "å®‰å…¨ä¿éšœ",
      "priority": 5,
      "inputs": ["motion_data", "door_sensor", "time_schedule"],
      "outputs": ["security_status", "intrusion_alert"],
      "dependencies": []
    },
    {
      "service_id": "data_analytics",
      "service_name": "æ•°æ®åˆ†ææœåŠ¡",
      "role": "æ•°æ®æ´å¯Ÿ",
      "priority": 3,
      "inputs": ["historical_data", "sensor_readings"],
      "outputs": ["trend_analysis", "predictions", "insights"],
      "dependencies": []
    },
    {
      "service_id": "notification_service",
      "service_name": "é€šçŸ¥æœåŠ¡",
      "role": "ä¿¡æ¯æ¨é€",
      "priority": 4,
      "inputs": ["alert_data", "notification_config"],
      "outputs": ["notification_sent", "delivery_status"],
      "dependencies": ["temperature_monitor", "security_monitoring"]
    }
  ],
  "execution_flow": "å¤šä¼ æ„Ÿå™¨ç›‘æ§ -> æ•°æ®åˆ†æå¤„ç† -> çŠ¶æ€è¯„ä¼° -> é€šçŸ¥æ¨é€",
  "data_flow": "ä¼ æ„Ÿå™¨æ•°æ® -> åˆ†æå¤„ç† -> çŠ¶æ€åˆ¤æ–­ -> ç”¨æˆ·é€šçŸ¥"
}
```

### 3. å®æ–½å»ºè®®
- éƒ¨ç½²é¡ºåºï¼šæ•°æ®åˆ†æ -> å„ç›‘æ§æœåŠ¡ -> é€šçŸ¥æœåŠ¡
- é…ç½®è¦ç‚¹ï¼šè°ƒæ•´ç›‘æ§é˜ˆå€¼ï¼Œé…ç½®é€šçŸ¥ç­–ç•¥ï¼Œä¼˜åŒ–æ•°æ®å¤„ç†æµç¨‹
- ç›‘æ§æŒ‡æ ‡ï¼šç³»ç»Ÿå“åº”æ—¶é—´ã€æ•°æ®å‡†ç¡®æ€§ã€é€šçŸ¥åŠæ—¶æ€§ã€ç”¨æˆ·æ»¡æ„åº¦
- é£é™©è¯„ä¼°ï¼šç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§ï¼Œé¿å…è¯¯æŠ¥ï¼Œä¿æŠ¤ç”¨æˆ·éšç§
"""
    
    def _parse_composition_response(self, response: str) -> Dict[str, Any]:
        """è§£æLLMå“åº”ï¼Œæå–æœåŠ¡ç»„åˆä¿¡æ¯"""
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSONéƒ¨åˆ†
            import re
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                composition_data = json.loads(json_str)
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œåˆ›å»ºé»˜è®¤ç»“æ„
                composition_data = {
                    "composition_id": f"composition_{int(time.time())}",
                    "services": [],
                    "execution_flow": "å¾…å®šä¹‰",
                    "data_flow": "å¾…å®šä¹‰"
                }
            
            # æ·»åŠ å…ƒæ•°æ®
            composition = {
                "id": composition_data.get("composition_id", f"composition_{int(time.time())}"),
                "created_at": datetime.now().isoformat(),
                "llm_response": response,
                "composition_data": composition_data,
                "status": "generated",
                "validation_results": {}
            }
            
            return composition
            
        except Exception as e:
            print(f"è§£æLLMå“åº”å¤±è´¥: {e}")
            return {
                "id": f"composition_{int(time.time())}",
                "created_at": datetime.now().isoformat(),
                "llm_response": response,
                "composition_data": {"services": []},
                "status": "parsing_failed",
                "error": str(e)
            }
    
    def _validate_composition(self, composition: Dict[str, Any]) -> Dict[str, Any]:
        """éªŒè¯æœåŠ¡ç»„åˆçš„å¯è¡Œæ€§"""
        validation_results = {
            "is_valid": True,
            "warnings": [],
            "errors": [],
            "suggestions": []
        }
        
        composition_data = composition.get("composition_data", {})
        services = composition_data.get("services", [])
        
        if not services:
            validation_results["is_valid"] = False
            validation_results["errors"].append("æœåŠ¡ç»„åˆä¸­æ²¡æœ‰å®šä¹‰ä»»ä½•æœåŠ¡")
            composition["validation_results"] = validation_results
            return composition
        
        # éªŒè¯æœåŠ¡æ˜¯å¦å­˜åœ¨
        available_service_ids = {service.id for service in self.available_services}
        for service in services:
            service_id = service.get("service_id", "")
            if service_id not in available_service_ids:
                validation_results["warnings"].append(f"æœåŠ¡ {service_id} ä¸åœ¨å¯ç”¨æœåŠ¡åˆ—è¡¨ä¸­")
        
        # éªŒè¯æœåŠ¡ä¾èµ–å…³ç³»
        service_ids = {service.get("service_id") for service in services}
        for service in services:
            dependencies = service.get("dependencies", [])
            for dep in dependencies:
                if dep not in service_ids:
                    validation_results["errors"].append(f"æœåŠ¡ {service.get('service_id')} ä¾èµ–çš„æœåŠ¡ {dep} ä¸åœ¨ç»„åˆä¸­")
                    validation_results["is_valid"] = False
        
        # éªŒè¯æ•°æ®æµè¿æ¥
        input_outputs = {}
        for service in services:
            service_id = service.get("service_id", "")
            inputs = service.get("inputs", [])
            outputs = service.get("outputs", [])
            input_outputs[service_id] = {"inputs": inputs, "outputs": outputs}
        
        # æ£€æŸ¥æ•°æ®æµè¿æ¥æ€§
        for service in services:
            service_id = service.get("service_id", "")
            inputs = service.get("inputs", [])
            dependencies = service.get("dependencies", [])
            
            for input_data in inputs:
                # æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦æœ‰æ¥æº
                has_source = False
                for dep in dependencies:
                    if dep in input_outputs:
                        dep_outputs = input_outputs[dep]["outputs"]
                        if any(input_data in output for output in dep_outputs):
                            has_source = True
                            break
                
                # æ£€æŸ¥è¾“å…¥æ•°æ®æ˜¯å¦æœ‰æ¥æºï¼Œæ’é™¤ä¼ æ„Ÿå™¨åŸå§‹æ•°æ®å’Œå¤–éƒ¨è¾“å…¥
                external_inputs = [
                    "sensor_data", "user_preferences", "schedule", "smoke_data", 
                    "temperature_data", "humidity_data", "light_data", "motion_data", 
                    "alert_data", "notification_config", "historical_data",
                    # æ–°å¢å¸¸è§çš„å¤–éƒ¨è¾“å…¥å’Œé…ç½®å‚æ•°
                    "target_humidity", "target_temperature", "door_sensor", 
                    "time_schedule", "schedule_config", "device_id", "parameters",
                    "trigger_conditions", "sensor_readings"
                ]
                
                if not has_source and input_data not in external_inputs:
                    validation_results["warnings"].append(f"æœåŠ¡ {service_id} çš„è¾“å…¥ {input_data} ç¼ºå°‘æ•°æ®æº")
        
        # æ·»åŠ ä¼˜åŒ–å»ºè®®
        if len(services) > 6:
            validation_results["suggestions"].append("æœåŠ¡ç»„åˆè¾ƒä¸ºå¤æ‚ï¼Œå»ºè®®è€ƒè™‘åˆ†é˜¶æ®µå®æ–½")
        
        high_priority_services = [s for s in services if int(s.get("priority", 0)) >= 4]
        if len(high_priority_services) > 3:
            validation_results["suggestions"].append("é«˜ä¼˜å…ˆçº§æœåŠ¡è¿‡å¤šï¼Œå»ºè®®é‡æ–°è¯„ä¼°ä¼˜å…ˆçº§åˆ†é…")
        
        composition["validation_results"] = validation_results
        composition["status"] = "validated" if validation_results["is_valid"] else "validation_failed"
        
        return composition
    
    def _record_composition(self, composition: Dict[str, Any], target_goal: str):
        """è®°å½•æœåŠ¡ç»„åˆå†å²"""
        history_entry = {
            "timestamp": datetime.now().isoformat(),
            "composition_id": composition["id"],
            "target_goal": target_goal,
            "status": composition["status"],
            "is_valid": composition.get("validation_results", {}).get("is_valid", False),
            "service_count": len(composition.get("composition_data", {}).get("services", []))
        }
        
        self.composition_history.append(history_entry)
        
        # é™åˆ¶å†å²è®°å½•æ•°é‡
        if len(self.composition_history) > 100:
            self.composition_history = self.composition_history[-50:]
    
    def optimize_composition(self, composition_id: str, performance_data: Dict[str, Any] = None,
                           user_feedback: str = None) -> Dict[str, Any]:
        """
        ä¼˜åŒ–ç°æœ‰æœåŠ¡ç»„åˆ
        
        Args:
            composition_id: æœåŠ¡ç»„åˆID
            performance_data: æ€§èƒ½æ•°æ®
            user_feedback: ç”¨æˆ·åé¦ˆ
            
        Returns:
            ä¼˜åŒ–åçš„æœåŠ¡ç»„åˆ
        """
        # æŸ¥æ‰¾ç°æœ‰ç»„åˆ
        existing_composition = self._find_composition(composition_id)
        if not existing_composition:
            return {"error": "æœªæ‰¾åˆ°æŒ‡å®šçš„æœåŠ¡ç»„åˆ"}
        
        # å‡†å¤‡ä¼˜åŒ–æç¤ºè¯
        optimization_prompt = self._prepare_optimization_prompt(
            existing_composition, performance_data, user_feedback
        )
        
        # è°ƒç”¨LLMè·å–ä¼˜åŒ–å»ºè®®
        llm_response = self._call_llm(optimization_prompt)
        
        # è§£æä¼˜åŒ–å»ºè®®
        optimization_result = {
            "original_composition_id": composition_id,
            "optimization_timestamp": datetime.now().isoformat(),
            "optimization_suggestions": llm_response,
            "status": "optimization_generated"
        }
        
        return optimization_result
    
    def _find_composition(self, composition_id: str) -> Optional[Dict[str, Any]]:
        """æŸ¥æ‰¾æœåŠ¡ç»„åˆ"""
        # è¿™é‡Œåº”è¯¥ä»æ•°æ®åº“æˆ–å­˜å‚¨ä¸­æŸ¥æ‰¾
        # ä¸ºäº†æ¼”ç¤ºï¼Œè¿”å›ä¸€ä¸ªç¤ºä¾‹ç»„åˆ
        return {
            "id": composition_id,
            "composition_data": {
                "services": [
                    {
                        "service_id": "temperature_monitor",
                        "service_name": "æ¸©åº¦ç›‘æ§æœåŠ¡",
                        "role": "ç¯å¢ƒç›‘æ§",
                        "priority": 4
                    }
                ]
            }
        }
    
    def _prepare_optimization_prompt(self, composition: Dict[str, Any], 
                                   performance_data: Dict[str, Any] = None,
                                   user_feedback: str = None) -> str:
        """å‡†å¤‡ä¼˜åŒ–æç¤ºè¯"""
        template = self.prompt_templates["service_optimization"]
        
        return template.format(
            current_composition=json.dumps(composition, indent=2, ensure_ascii=False),
            performance_data=json.dumps(performance_data or {}, indent=2, ensure_ascii=False),
            user_feedback=user_feedback or "æš‚æ— ç”¨æˆ·åé¦ˆ",
            optimization_goals="æé«˜æ€§èƒ½ã€é™ä½æˆæœ¬ã€æ”¹å–„ç”¨æˆ·ä½“éªŒ"
        )
    
    def troubleshoot_composition(self, problem_description: str, 
                               error_messages: List[str] = None,
                               related_services: List[str] = None) -> Dict[str, Any]:
        """
        æ•…éšœæ’é™¤
        
        Args:
            problem_description: é—®é¢˜æè¿°
            error_messages: é”™è¯¯ä¿¡æ¯
            related_services: ç›¸å…³æœåŠ¡
            
        Returns:
            æ•…éšœæ’é™¤æ–¹æ¡ˆ
        """
        # å‡†å¤‡æ•…éšœæ’é™¤æç¤ºè¯
        troubleshooting_prompt = self._prepare_troubleshooting_prompt(
            problem_description, error_messages, related_services
        )
        
        # è°ƒç”¨LLMè·å–æ•…éšœæ’é™¤å»ºè®®
        llm_response = self._call_llm(troubleshooting_prompt)
        
        return {
            "problem_description": problem_description,
            "troubleshooting_timestamp": datetime.now().isoformat(),
            "diagnosis_and_solution": llm_response,
            "status": "troubleshooting_completed"
        }
    
    def _prepare_troubleshooting_prompt(self, problem_description: str,
                                      error_messages: List[str] = None,
                                      related_services: List[str] = None) -> str:
        """å‡†å¤‡æ•…éšœæ’é™¤æç¤ºè¯"""
        template = self.prompt_templates["trouble_shooting"]
        
        return template.format(
            problem_description=problem_description,
            error_messages="\n".join(error_messages or []),
            related_services=", ".join(related_services or []),
            system_status="æ­£å¸¸è¿è¡Œ"
        )
    
    def get_available_services(self) -> List[Dict[str, Any]]:
        """è·å–å¯ç”¨æœåŠ¡åˆ—è¡¨"""
        return [service.to_dict() for service in self.available_services]
    
    def get_composition_history(self) -> List[Dict[str, Any]]:
        """è·å–æœåŠ¡ç»„åˆå†å²"""
        return self.composition_history.copy()
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_compositions = len(self.composition_history)
        valid_compositions = sum(1 for comp in self.composition_history if comp.get("is_valid", False))
        
        return {
            "å¯ç”¨æœåŠ¡æ•°é‡": len(self.available_services),
            "å†å²ç»„åˆæ€»æ•°": total_compositions,
            "æœ‰æ•ˆç»„åˆæ•°é‡": valid_compositions,
            "æˆåŠŸç‡": f"{valid_compositions/total_compositions*100:.1f}%" if total_compositions > 0 else "0%",
            "æ¨¡å‹ç±»å‹": self.model_type,
            "æœ€è¿‘ç»„åˆæ—¶é—´": self.composition_history[-1]["timestamp"] if self.composition_history else "æ— "
        }

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæœåŠ¡ç»„åˆå™¨
    composer = LLMServiceComposer()
    
    print("=== å¤§æ¨¡å‹æœåŠ¡ç»„åˆæ¼”ç¤º ===")
    
    # æ¼”ç¤º1: ç«ç¾å®‰å…¨ç»„åˆ
    print("\n1. ç«ç¾å®‰å…¨æœåŠ¡ç»„åˆ")
    fire_composition = composer.compose_services(
        target_goal="å»ºç«‹ä¸€ä¸ªæ™ºèƒ½ç«ç¾å®‰å…¨ç³»ç»Ÿï¼Œèƒ½å¤ŸåŠæ—¶æ£€æµ‹ç«ç¾é£é™©å¹¶è‡ªåŠ¨å“åº”",
        sensor_data={"smoke_level": 180, "temperature": 35},
        constraints=["å“åº”æ—¶é—´å°äº30ç§’", "è¯¯æŠ¥ç‡ä½äº5%"]
    )
    print(f"ç»„åˆID: {fire_composition['id']}")
    print(f"çŠ¶æ€: {fire_composition['status']}")
    print(f"åŒ…å«æœåŠ¡æ•°: {len(fire_composition.get('composition_data', {}).get('services', []))}")
    
    # æ¼”ç¤º2: èˆ’é€‚åº¦ç®¡ç†ç»„åˆ
    print("\n2. èˆ’é€‚åº¦ç®¡ç†æœåŠ¡ç»„åˆ")
    comfort_composition = composer.compose_services(
        target_goal="åˆ›å»ºæ™ºèƒ½èˆ’é€‚åº¦ç®¡ç†ç³»ç»Ÿï¼Œè‡ªåŠ¨ç»´æŒæœ€ä½³å±…ä½ç¯å¢ƒ",
        sensor_data={"temperature": 28, "humidity": 75, "light": 200},
        constraints=["èƒ½è€—å¢åŠ ä¸è¶…è¿‡20%", "è°ƒèŠ‚å“åº”æ—¶é—´å°äº5åˆ†é’Ÿ"]
    )
    print(f"ç»„åˆID: {comfort_composition['id']}")
    print(f"çŠ¶æ€: {comfort_composition['status']}")
    
    # æ¼”ç¤º3: æŸ¥çœ‹å¯ç”¨æœåŠ¡
    print("\n3. å¯ç”¨æœåŠ¡åˆ—è¡¨")
    services = composer.get_available_services()
    for service in services[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
        print(f"- {service['name']}: {service['description']}")
    
    # æ¼”ç¤º4: ç»Ÿè®¡ä¿¡æ¯
    print("\n4. ç»Ÿè®¡ä¿¡æ¯")
    stats = composer.get_statistics()
    print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    # æ¼”ç¤º5: æ•…éšœæ’é™¤
    print("\n5. æ•…éšœæ’é™¤æ¼”ç¤º")
    troubleshooting = composer.troubleshoot_composition(
        problem_description="æ¸©åº¦ç›‘æ§æœåŠ¡é¢‘ç¹æŠ¥è­¦ï¼Œä½†å®é™…æ¸©åº¦æ­£å¸¸",
        error_messages=["æ¸©åº¦é˜ˆå€¼è¶…é™", "ä¼ æ„Ÿå™¨æ•°æ®å¼‚å¸¸"],
        related_services=["temperature_monitor", "notification_service"]
    )
    print(f"æ•…éšœæ’é™¤çŠ¶æ€: {troubleshooting['status']}")
